# -*- coding: utf-8 -*-
"""Blog_Entrada_1_PTF2026.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Vfr3c6uDdhhEJJcXbMF4Lfs1jQxJ5D8o

# DATA
"""

import yfinance as yf
import pandas as pd
import numpy as np

# 1. PORTFOLIO CONFIGURATION
# We define a diversified set of tickers: Quality/Intl Factors, Emerging Markets,
# Precious Metals, Managed Futures (DBMF), Crypto, and the S&P 500.
tickers = ["QUAL", "IQLT", "EMGF", "GLTR", "DBMF", "ARGT", "BTC-USD", "ETH-USD", "VOO"]
print(f"Initializing data retrieval for {len(tickers)} assets...")

# 2. DATA DOWNLOAD (HISTORICAL PRICES)
# 'period="max"' retrieves the entire price history from each ticker's inception date.
# We focus on the 'Close' price for simplicity in calculating returns.
data = yf.download(tickers, period="max", progress=False)['Close']

# 3. DATA AUDIT AND PROCESSING
# We create a list to store time-series metrics for each asset.
report_data = []

for ticker in tickers:
    if ticker in data.columns:
        # We drop NaN values to find the specific active trading window for each ticker
        series = data[ticker].dropna()

        if not series.empty:
            start_date = series.index.min()
            end_date = series.index.max()
            trading_days = len(series)

            # Estimate years based on the standard ~252 trading days per year
            years_of_history = trading_days / 252

            report_data.append({
                'Ticker': ticker,
                'Start Date': start_date.date(),
                'End Date': end_date.date(),
                'Days Logged': trading_days,
                'Years (Approx)': round(years_of_history, 2)
            })

# 4. STRUCTURED REPORT GENERATION
# Convert the list to a DataFrame for clean visualization and sort by Start Date.
df_report = pd.DataFrame(report_data).sort_values(by='Start Date')

print("\n" + "="*60)
print("             HISTORICAL DATA AVAILABILITY REPORT")
print("="*60)
print(df_report.to_string(index=False))

# 5. OPTIMIZATION WINDOW ANALYSIS
# This is critical: To perform portfolio optimization
# all assets must share the same date range.
# Using dropna() on the entire DataFrame finds the "intersection" start date.
common_start_date = data.dropna().index.min().date()

print("\n" + "-"*60)
print(f"MULTI-ASSET OPTIMIZATION ANALYSIS:")
print(f"To analyze all assets simultaneously, your lookback period")
print(f"must begin at the latest inception date: {common_start_date}")
print("-"*60)

# 1. Formatting and Cleaning
pd.options.display.float_format = '{:,.2f}'.format
data = data.dropna()
data.index = pd.to_datetime(data.index)

# --- Output Results ---
print("DATASET PREVIEW: ASSETS IN USD")
print("=" * 85)
print(f"Showing start and end of the converted dataset:\n")

# Display first and last 5 rows
display(data.head())
print("\n" + "."*85 + "\n")
display(data.tail())
print("=" * 85)

"""Metrics"""

from scipy.stats import norm

# --- 1. CONFIGURATION ---
pd.options.display.float_format = '{:,.2f}'.format
pd.set_option('display.max_columns', None)  # Ensures no column skipping
pd.set_option('display.width', 1000)        # Prevents line breaks
TRADING_DAYS = 252
rf_rate = 0.03

# --- 2. DATA PROCESSING ---
returns = np.log(data / data.shift(1)).dropna()

def get_asset_metrics(ticker):
    series = returns[ticker]
    prices = data[ticker]

    # Performance & Volatility
    ann_ret = series.mean() * TRADING_DAYS
    ann_vol = series.std() * np.sqrt(TRADING_DAYS)

    # Sharpe Ratio in Basis Points (bps) - Fixed calculation
    sharpe_bps = ((ann_ret - rf_rate)/ ann_vol) * 100

    # --- DETAILED DRAWDOWN ANALYSIS ---
    roll_max = prices.cummax()
    drawdowns = (prices - roll_max) / roll_max
    max_dd = drawdowns.min()

    # Key Dates
    trough_date = drawdowns.idxmin()
    peak_date = prices[:trough_date].idxmax()

    # Phase 1: Contraction (Peak to Trough)
    days_falling = (trough_date - peak_date).days

    # Phase 2: Recovery (Trough to previous Peak)
    post_trough_prices = prices[trough_date:]
    recovery_series = post_trough_prices[post_trough_prices >= prices[peak_date]]

    if not recovery_series.empty:
        recovery_date = recovery_series.index[0]
        days_recovering = (recovery_date - trough_date).days
        recovery_status = recovery_date.date()
    else:
        recovery_status = "Ongoing"
        days_recovering = (prices.index[-1] - trough_date).days

# --- NON-PARAMETRIC RISK (Historical Simulation - 1 Day) ---
    def calc_hist_risk(series, confidence_level):
        # We look for the alpha percentile (e.g., 1% or 5%)
        alpha = 1 - confidence_level

        # VaR: The empirical quantile
        # We report it as a positive magnitude of loss
        var_1d = -np.percentile(series, alpha * 100)

        # CVaR: The average of losses exceeding the VaR
        tail_losses = series[series <= -var_1d]
        cvar_1d = -tail_losses.mean()

        return var_1d, cvar_1d

    # Calculate 1-Day Historical Metrics
    v95_1d, cv95_1d = calc_hist_risk(series, 0.95)
    v99_1d, cv99_1d = calc_hist_risk(series, 0.99)

    return {
        'Ticker': ticker,
        'Ann_Return %': ann_ret * 100,
        'Ann_Vol %': ann_vol * 100,
        'Sharpe_bps': sharpe_bps,
        'Max_DD %': max_dd * 100,
        'Days_Fall': days_falling,
        'Days_Recov': days_recovering,
        'Peak_Date': peak_date.date(),
        'Trough_Date': trough_date.date(),
        'Recov_Date': recovery_status,
        'VaR_95 %': v95_1d * 100,
        'CVaR_95 %': cv95_1d * 100,
        'VaR_99 %': v99_1d * 100,
        'CVaR_99 %': cv99_1d * 100
    }

# --- 3. EXECUTION ---
metrics_results = [get_asset_metrics(t) for t in data.columns]
df_report = pd.DataFrame(metrics_results).set_index('Ticker')

# Grouped Columns for horizontal consistency
perf_risk_cols = ['Ann_Return %', 'Ann_Vol %', 'Sharpe_bps', 'VaR_95 %', 'CVaR_95 %', 'VaR_99 %', 'CVaR_99 %']
drawdown_cols = ['Max_DD %', 'Days_Fall', 'Days_Recov', 'Peak_Date', 'Trough_Date', 'Recov_Date']

# --- 4. PROFESSIONAL CONSOLE OUTPUT ---
print("\n" + "="*130)
print("ASSET REPORT: PERFORMANCE, RISK & DRAWDOWN ANALYSIS")
print("="*130)

print("\n SECTION 1: PERFORMANCE & TAIL RISK PROFILE")
print("-" * 130)
print(df_report[perf_risk_cols])



print("\n SECTION 2: DRAWDOWN DYNAMICS (CONTRACTION & RECOVERY)")
print("-" * 130)
print(df_report[drawdown_cols])



print("\n SECTION 3: CROSS-ASSET CORRELATION MATRIX (%)")
print("-" * 130)
print(returns.corr() * 100)

print("\n" + "="*130)
print(f"Report Period: {returns.index[0].date()} to {returns.index[-1].date()} | Trading Days: {TRADING_DAYS}")
print("="*130)